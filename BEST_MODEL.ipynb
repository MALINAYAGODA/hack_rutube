{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "OWrIm_ntehui"
   },
   "outputs": [],
   "source": [
    "!pip install av==11.0.0 decord sentence_transformers faiss-cpu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "aUSSUrN0bOwW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import InputExample, losses, SentenceTransformer\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import json\n",
    "import faiss\n",
    "from decord import VideoReader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "yzoY2O_Uc3j5"
   },
   "outputs": [],
   "source": [
    "with open('/home/jovyan/lost+found/results_2.json', 'r', encoding='utf-8') as f:\n",
    "    data2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "QyXvP4wCNI2s"
   },
   "outputs": [],
   "source": [
    "train_data_cat = pd.read_csv(\"/home/jovyan/lost+found/train_data_categories.csv\")\n",
    "IAB_tags = pd.read_csv(\"/home/jovyan/lost+found/IAB_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Zpf3C3tmR1NZ"
   },
   "outputs": [],
   "source": [
    "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    if seg_len - converted_len <= 0:\n",
    "        start_idx = 0\n",
    "        end_idx = seg_len\n",
    "    else:\n",
    "        end_idx = np.random.randint(converted_len, seg_len)\n",
    "        start_idx = end_idx - converted_len\n",
    "    indices = np.linspace(start_idx, end_idx - 1, num=clip_len)\n",
    "    indices = np.clip(indices, 0, seg_len - 1).astype(np.int64)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "9e2ac8470f5b4e75ad78254670fb7d13",
      "69ee207e54f84718bf801a2298ee0724",
      "8cbc19b0ee374d1fb49973db0e697d11",
      "253e38d324674a038945336da4806006",
      "a76a2326b719446fb0ac4d807e2dce78",
      "4de140fee82242e8893073b0ace3a862",
      "1ddf7fca3d04406da5abf1ceb1196ecd",
      "f7da282a6c8d43fc93de4e4a853b989c"
     ]
    },
    "id": "2pthdTa7S27s",
    "outputId": "e5d86286-c933-4c08-9dbb-c8949edd4d7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import XCLIPProcessor, XCLIPVisionModel\n",
    "\n",
    "model_name = \"microsoft/xclip-base-patch16-zero-shot\" # microsoft/xclip-base-patch32\n",
    "\n",
    "processor = XCLIPProcessor.from_pretrained(model_name)\n",
    "video_model = XCLIPVisionModel.from_pretrained(model_name).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "3NM6FGH4X-Ue"
   },
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(\n",
    "            self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0.,\n",
    "            proj_drop=0., attn_head_dim=None, out_dim=None):\n",
    "        super().__init__()\n",
    "        if out_dim is None:\n",
    "            out_dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        if attn_head_dim is not None:\n",
    "            head_dim = attn_head_dim\n",
    "        all_head_dim = head_dim * self.num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        assert all_head_dim == dim\n",
    "\n",
    "        self.q = nn.Linear(dim, all_head_dim, bias=False)\n",
    "        self.k = nn.Linear(dim, all_head_dim, bias=False)\n",
    "        self.v = nn.Linear(dim, all_head_dim, bias=False)\n",
    "\n",
    "        if qkv_bias:\n",
    "            self.q_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
    "            self.k_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
    "            self.v_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
    "        else:\n",
    "            self.q_bias = None\n",
    "            self.k_bias = None\n",
    "            self.v_bias = None\n",
    "\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(all_head_dim, out_dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x, k=None, v=None):\n",
    "        B, N, C = x.shape\n",
    "        N_k = k.shape[1]\n",
    "        N_v = v.shape[1]\n",
    "\n",
    "        q_bias, k_bias, v_bias = None, None, None\n",
    "        if self.q_bias is not None:\n",
    "            q_bias = self.q_bias\n",
    "            k_bias = self.k_bias\n",
    "            v_bias = self.v_bias\n",
    "\n",
    "        q = F.linear(input=x, weight=self.q.weight, bias=q_bias)\n",
    "        q = q.reshape(B, N, 1, self.num_heads, -1).permute(2, 0, 3, 1, 4).squeeze(0)  # (B, N_head, N_q, dim)\n",
    "\n",
    "        k = F.linear(input=k, weight=self.k.weight, bias=k_bias)\n",
    "        k = k.reshape(B, N_k, 1, self.num_heads, -1).permute(2, 0, 3, 1, 4).squeeze(0)\n",
    "\n",
    "        v = F.linear(input=v, weight=self.v.weight, bias=v_bias)\n",
    "        v = v.reshape(B, N_v, 1, self.num_heads, -1).permute(2, 0, 3, 1, 4).squeeze(0)\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))  # (B, N_head, N_q, N_k)\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, -1)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "WSU78eA7nGwI"
   },
   "outputs": [],
   "source": [
    "data = train_data_cat\n",
    "taxonomy = IAB_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "6a332c6768ce482387f10129529187d8",
      "c565309629a7461dbd2b8d034820b943",
      "7653a0bfaaa34b5a9840e169b4b32a69",
      "149fefe2d743481da58c825216e09d1e",
      "c3f0c2e9550e451ab9c2efab9b77fe76",
      "ca50f77d47f14bcdaf5445048e7426f2",
      "68b487220e6f4a6fa6797c0324356d1a",
      "1a3220aef5ed44da9562cbd3319f5dca",
      "cc38bf6b60c94524b5f6fa40bcfe5233",
      "97a81df00e1f45aea402958bfa3a3619"
     ]
    },
    "id": "H38TNAG5iHhR",
    "outputId": "d6c7a999-ddfd-4f20-cd14-09eeb5fe364d"
   },
   "outputs": [],
   "source": [
    "text_model = SentenceTransformer('intfloat/multilingual-e5-large-instruct').to('cuda')\n",
    "dim = 1024 # размер вектора эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "9B0Am4NwQPc-"
   },
   "outputs": [],
   "source": [
    "audio_df = pd.DataFrame(list(data2.items()), columns=['filename', 'transcription'])\n",
    "audio_df['filename'] = audio_df['filename'].apply(lambda l: l.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwTlKFSK41Hl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Hhk0uutf41Hl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = '/home/jovyan/lost+found/videos_2/'\n",
    "\n",
    "# Получаем список всех файлов и папок в директории\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Фильтруем, оставляя только файлы (если нужно)\n",
    "files = [f[:-4] for f in files if os.path.isfile(os.path.join(directory, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "3DzYwrMJ41Hm",
    "outputId": "d8e7b567-2e1b-443d-dcaa-09f603dea14b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1049, 2)\n",
      "(934, 2)\n"
     ]
    }
   ],
   "source": [
    "print(audio_df.shape)\n",
    "is_cool = [i in files for i in audio_df.filename.tolist()]\n",
    "audio_df = audio_df[is_cool]\n",
    "print(audio_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hvOtyoWG41Hm",
    "outputId": "547941ca-2c63-44a5-d680-71e2afe9778a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1049, 4)\n",
      "(934, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "is_cool = [i in files for i in data.video_id.tolist()]\n",
    "data = data[is_cool]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "rrINjKUxSZqJ"
   },
   "outputs": [],
   "source": [
    "data = pd.merge(data.reset_index(drop=True), audio_df.reset_index(drop=True), how='left', left_on='video_id', right_on='filename')\n",
    "data = data.drop('filename', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "Vm45Q_S_XDrX",
    "outputId": "519f28c3-5eff-4fc3-86db-90547947806a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>4354a1ad8bf75f42466420f4b52dcbcd</td>\n",
       "      <td>Артмеханика. Концерт группы Диктофон.</td>\n",
       "      <td>Концерт группы Диктофон.</td>\n",
       "      <td>Массовая культура, Карьера, События и достопри...</td>\n",
       "      <td>Woo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>a8033ba9f69362b009d852b2a9d76749</td>\n",
       "      <td>Три лошадиные силы I Выпуск №14</td>\n",
       "      <td>В этом выпуске парни помогают Деду Морозу разв...</td>\n",
       "      <td>Транспорт, Массовая культура</td>\n",
       "      <td>Дома, что ли?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             video_id                                  title  \\\n",
       "222  4354a1ad8bf75f42466420f4b52dcbcd  Артмеханика. Концерт группы Диктофон.   \n",
       "502  a8033ba9f69362b009d852b2a9d76749        Три лошадиные силы I Выпуск №14   \n",
       "\n",
       "                                           description  \\\n",
       "222                           Концерт группы Диктофон.   \n",
       "502  В этом выпуске парни помогают Деду Морозу разв...   \n",
       "\n",
       "                                                  tags  transcription  \n",
       "222  Массовая культура, Карьера, События и достопри...           Woo!  \n",
       "502                       Транспорт, Массовая культура  Дома, что ли?  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJbOdp0K41Hm"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "U6mTsiTtOkKl"
   },
   "outputs": [],
   "source": [
    "audio_model = SentenceTransformer('intfloat/multilingual-e5-large-instruct').to('cuda')\n",
    "dim = 1024 # размер вектора эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "0RruAImEdl1c"
   },
   "outputs": [],
   "source": [
    "template = [(isinstance(i, str)) for i in  data[\"tags\"].tolist()]\n",
    "data = data[template]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8fgLX5jVGfbE"
   },
   "outputs": [],
   "source": [
    "title_description = []\n",
    "tag_list = []\n",
    "video_ids = []\n",
    "audio_text = []\n",
    "\n",
    "for i in data.iterrows():\n",
    "  tags = i[1].tags.split(\", \")\n",
    "  title = i[1].title\n",
    "  description = i[1].description\n",
    "  video_id = i[1].video_id\n",
    "  for j in range(len(tags)):\n",
    "    tag_list.append(tags[j])\n",
    "    title_description.append(\"Title: \" + title + \". Description: \" + description)\n",
    "    video_ids.append(video_id)\n",
    "    audio_text.append(i[1].transcription)\n",
    "\n",
    "df_work = pd.DataFrame({\"video_id\": video_ids, \"title_description\": title_description,\n",
    "                        \"audio_text\": audio_text, \"tag_list\": tag_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "W4LQnCKw1UFl"
   },
   "outputs": [],
   "source": [
    "#df_work['title_description_vector'] = df_work['title_description'].apply(lambda l: text_model.encode(l, convert_to_tensor=True).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Gxv3nQyOXshr"
   },
   "outputs": [],
   "source": [
    "#df_work['audio_text_vector'] = df_work['audio_text'].apply(lambda l: audio_model.encode(l, convert_to_tensor=True).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "1Tena4TKodtV"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_work, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "2-hPdCLIYBks"
   },
   "outputs": [],
   "source": [
    "class FusionEmbedModel(nn.Module):\n",
    "  def __init__(self, video_emb_size, text_emb_size, audio_text_emb_size,\n",
    "               out_emb_size=768, num_heads=8):\n",
    "    super().__init__()\n",
    "    self.description_title_video_cross_attn = CrossAttention(\n",
    "            dim=text_emb_size,\n",
    "            num_heads=num_heads,\n",
    "            out_dim=text_emb_size\n",
    "        )\n",
    "\n",
    "    self.audio_text_video_cross_attn = CrossAttention(\n",
    "        \n",
    "        dim=audio_text_emb_size,\n",
    "        num_heads=num_heads,\n",
    "        out_dim=audio_text_emb_size\n",
    "    )\n",
    "\n",
    "    total_emb_size = text_emb_size + audio_text_emb_size\n",
    "    self.linear_video_proj = nn.Linear(video_emb_size, text_emb_size)\n",
    "    self.out_proj = nn.Linear(total_emb_size, out_emb_size)\n",
    "\n",
    "  def forward(self, description_title_emb, audio_text_emb, video_emb):\n",
    "        # description_title_emb: (B, N_desc, C_text)\n",
    "        # audio_text_emb: (B, N_audio, C_audio_text)\n",
    "        # video_emb: (B, N_video, C_video)\n",
    "\n",
    "        video_emb = self.linear_video_proj(video_emb)\n",
    "\n",
    "        description_title_video_attn = self.description_title_video_cross_attn(\n",
    "            x=description_title_emb, k=video_emb, v=video_emb\n",
    "        )  # (B, N_desc, C_text)\n",
    "\n",
    "        audio_text_video_attn = self.audio_text_video_cross_attn(\n",
    "            x=audio_text_emb, k=video_emb, v=video_emb\n",
    "        )  # (B, N_audio, C_audio_text)\n",
    "\n",
    "        # average pooling -> bottleneck (we can try different strategies)\n",
    "        description_title_attn_pooled = description_title_video_attn.mean(dim=1)  # (B, C_text)\n",
    "        audio_text_attn_pooled = audio_text_video_attn.mean(dim=1)    # (B, C_audio_text)\n",
    "\n",
    "        cat_embs = torch.cat([\n",
    "            description_title_attn_pooled,\n",
    "            audio_text_attn_pooled\n",
    "        ], dim=-1)  # (B, total_emb_size)\n",
    "\n",
    "        universal_emb = self.out_proj(cat_embs)  # (B, out_emb_size)\n",
    "        return universal_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "iBB1ywPboq-4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/image_processing_utils.py:41: UserWarning: The following named arguments are not valid for `VideoMAEImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "video_model.eval()\n",
    "video_embs_dict = dict()\n",
    "video_embs = []\n",
    "for i in train_df.iterrows():\n",
    "  # видео эмбеддинги засовываем в train_df в новую колонку\n",
    "  video_path = \"/home/jovyan/lost+found/videos_2/\" + str(i[1].video_id) + \".mp4\" # поменять на директорию, где хранятся видео, типо video_id = \"folder/\" + video_id\n",
    "  if video_path in video_embs_dict:\n",
    "    video_embs.append(video_embs_dict[video_path])\n",
    "  else:\n",
    "    vr = VideoReader(video_path)\n",
    "    seg_len = len(vr)\n",
    "    clip_len = 32 # для конкретной модели (microsoft/xclip-base-patch16-zero-shot)\n",
    "    frame_sample_rate = 1\n",
    "    indices = sample_frame_indices(clip_len=clip_len, frame_sample_rate=frame_sample_rate, seg_len=seg_len)\n",
    "    video = vr.get_batch(indices).asnumpy()  # (clip_len, H, W, C)\n",
    "    inputs = processor(videos=list(video), return_tensors=\"pt\", padding=True).to('cuda')\n",
    "    pixel_values = inputs['pixel_values']\n",
    "    batch_size, num_frames, channels, height, width = pixel_values.shape\n",
    "    pixel_values = pixel_values.view(-1, channels, height, width)  # [batch_size * num_frames, channels, height, width]\n",
    "    inputs['pixel_values'] = pixel_values.to('cuda')\n",
    "    with torch.no_grad():\n",
    "      outputs = video_model(**inputs)\n",
    "    frame_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    frame_embeddings = frame_embeddings.view(batch_size, num_frames, -1)\n",
    "    # average pooling over frame_embeddings\n",
    "    video_embedding = frame_embeddings.mean(dim=1) # (batch_size, emb_size) # надеюсь emb_size=1024 иначе еще линейный слой\n",
    "    video_embs.append(video_embedding)\n",
    "    video_embs_dict[video_path] = video_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "IFDLyEsV41Hn"
   },
   "outputs": [],
   "source": [
    "train_df['video_emb'] = [i.cpu().detach() for i in video_embs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbwrX68-41Hn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "TCe9hGZw41Ho",
    "outputId": "52cb8fd2-6c47-4a48-c3d5-018f15cc7adf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title_description</th>\n",
       "      <th>audio_text</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>video_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>9d37073c63008c784bf95a8a4d1715d5</td>\n",
       "      <td>Title: Punch Box. Серия 1. Пельмень vs Керам. ...</td>\n",
       "      <td>Первый кулак России, который сделан нокаут в т...</td>\n",
       "      <td>Массовая культура</td>\n",
       "      <td>[[tensor(-0.1769), tensor(0.2236), tensor(0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>cb8f4c48fd10af6768c3a89a5f9ab2f7</td>\n",
       "      <td>Title: Команда 3/21 в ГрандТуре «Байкальская м...</td>\n",
       "      <td>Погнали</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>[[tensor(-0.2604), tensor(-0.0189), tensor(0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              video_id  \\\n",
       "1237  9d37073c63008c784bf95a8a4d1715d5   \n",
       "1107  cb8f4c48fd10af6768c3a89a5f9ab2f7   \n",
       "\n",
       "                                      title_description  \\\n",
       "1237  Title: Punch Box. Серия 1. Пельмень vs Керам. ...   \n",
       "1107  Title: Команда 3/21 в ГрандТуре «Байкальская м...   \n",
       "\n",
       "                                             audio_text           tag_list  \\\n",
       "1237  Первый кулак России, который сделан нокаут в т...  Массовая культура   \n",
       "1107                                            Погнали        Путешествия   \n",
       "\n",
       "                                              video_emb  \n",
       "1237  [[tensor(-0.1769), tensor(0.2236), tensor(0.00...  \n",
       "1107  [[tensor(-0.2604), tensor(-0.0189), tensor(0.0...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Z2MPBlfNbVjn"
   },
   "outputs": [],
   "source": [
    "general_tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "WKGyos6V41Ho"
   },
   "outputs": [],
   "source": [
    "target_model = SentenceTransformer('intfloat/multilingual-e5-large-instruct').to('cuda')\n",
    "dim = 1024 # размерность эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "MYY8DM5c41Ho"
   },
   "outputs": [],
   "source": [
    "fusion_model = FusionEmbedModel(video_emb_size=768,\n",
    "                                text_emb_size=1024,\n",
    "                                audio_text_emb_size=1024,\n",
    "                                out_emb_size=1024, num_heads=8).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "hm0MZ8ebbPN1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/71 [00:00<00:34,  2.03it/s]\u001b[A\n",
      "  3%|▎         | 2/71 [00:00<00:31,  2.21it/s]\u001b[A\n",
      "  4%|▍         | 3/71 [00:01<00:34,  2.00it/s]\u001b[A\n",
      "  6%|▌         | 4/71 [00:01<00:32,  2.03it/s]\u001b[A\n",
      "  7%|▋         | 5/71 [00:02<00:29,  2.25it/s]\u001b[A\n",
      "  8%|▊         | 6/71 [00:02<00:28,  2.26it/s]\u001b[A\n",
      " 10%|▉         | 7/71 [00:03<00:28,  2.24it/s]\u001b[A\n",
      " 11%|█▏        | 8/71 [00:03<00:26,  2.38it/s]\u001b[A\n",
      " 13%|█▎        | 9/71 [00:04<00:27,  2.26it/s]\u001b[A\n",
      " 14%|█▍        | 10/71 [00:04<00:27,  2.25it/s]\u001b[A\n",
      " 15%|█▌        | 11/71 [00:04<00:26,  2.23it/s]\u001b[A\n",
      " 17%|█▋        | 12/71 [00:05<00:25,  2.35it/s]\u001b[A\n",
      " 18%|█▊        | 13/71 [00:05<00:25,  2.25it/s]\u001b[A\n",
      " 20%|█▉        | 14/71 [00:06<00:24,  2.36it/s]\u001b[A\n",
      " 21%|██        | 15/71 [00:06<00:23,  2.35it/s]\u001b[A\n",
      " 23%|██▎       | 16/71 [00:07<00:23,  2.37it/s]\u001b[A\n",
      " 24%|██▍       | 17/71 [00:07<00:24,  2.24it/s]\u001b[A\n",
      " 25%|██▌       | 18/71 [00:07<00:23,  2.30it/s]\u001b[A\n",
      " 27%|██▋       | 19/71 [00:08<00:23,  2.26it/s]\u001b[A\n",
      " 28%|██▊       | 20/71 [00:08<00:23,  2.16it/s]\u001b[A\n",
      " 30%|██▉       | 21/71 [00:09<00:22,  2.20it/s]\u001b[A\n",
      " 31%|███       | 22/71 [00:09<00:23,  2.12it/s]\u001b[A\n",
      " 32%|███▏      | 23/71 [00:10<00:22,  2.17it/s]\u001b[A\n",
      " 34%|███▍      | 24/71 [00:10<00:21,  2.16it/s]\u001b[A\n",
      " 35%|███▌      | 25/71 [00:11<00:21,  2.18it/s]\u001b[A\n",
      " 37%|███▋      | 26/71 [00:11<00:19,  2.35it/s]\u001b[A\n",
      " 38%|███▊      | 27/71 [00:11<00:18,  2.44it/s]\u001b[A\n",
      " 39%|███▉      | 28/71 [00:12<00:18,  2.31it/s]\u001b[A\n",
      " 41%|████      | 29/71 [00:12<00:18,  2.25it/s]\u001b[A\n",
      " 42%|████▏     | 30/71 [00:13<00:17,  2.38it/s]\u001b[A\n",
      " 44%|████▎     | 31/71 [00:13<00:17,  2.30it/s]\u001b[A\n",
      " 45%|████▌     | 32/71 [00:14<00:17,  2.20it/s]\u001b[A\n",
      " 46%|████▋     | 33/71 [00:14<00:16,  2.33it/s]\u001b[A\n",
      " 48%|████▊     | 34/71 [00:15<00:16,  2.21it/s]\u001b[A\n",
      " 49%|████▉     | 35/71 [00:15<00:17,  2.04it/s]\u001b[A\n",
      " 51%|█████     | 36/71 [00:16<00:16,  2.15it/s]\u001b[A\n",
      " 52%|█████▏    | 37/71 [00:16<00:16,  2.10it/s]\u001b[A\n",
      " 54%|█████▎    | 38/71 [00:17<00:15,  2.13it/s]\u001b[A\n",
      " 55%|█████▍    | 39/71 [00:17<00:14,  2.17it/s]\u001b[A\n",
      " 56%|█████▋    | 40/71 [00:17<00:14,  2.12it/s]\u001b[A\n",
      " 58%|█████▊    | 41/71 [00:18<00:13,  2.25it/s]\u001b[A\n",
      " 59%|█████▉    | 42/71 [00:18<00:12,  2.40it/s]\u001b[A\n",
      " 61%|██████    | 43/71 [00:19<00:12,  2.24it/s]\u001b[A\n",
      " 62%|██████▏   | 44/71 [00:19<00:12,  2.22it/s]\u001b[A\n",
      " 63%|██████▎   | 45/71 [00:20<00:11,  2.29it/s]\u001b[A\n",
      " 65%|██████▍   | 46/71 [00:20<00:10,  2.30it/s]\u001b[A\n",
      " 66%|██████▌   | 47/71 [00:21<00:10,  2.22it/s]\u001b[A\n",
      " 68%|██████▊   | 48/71 [00:21<00:10,  2.24it/s]\u001b[A\n",
      " 69%|██████▉   | 49/71 [00:21<00:09,  2.34it/s]\u001b[A\n",
      " 70%|███████   | 50/71 [00:22<00:09,  2.29it/s]\u001b[A\n",
      " 72%|███████▏  | 51/71 [00:22<00:08,  2.37it/s]\u001b[A\n",
      " 73%|███████▎  | 52/71 [00:23<00:08,  2.34it/s]\u001b[A\n",
      " 75%|███████▍  | 53/71 [00:23<00:07,  2.30it/s]\u001b[A\n",
      " 76%|███████▌  | 54/71 [00:24<00:07,  2.18it/s]\u001b[A\n",
      " 77%|███████▋  | 55/71 [00:24<00:08,  1.99it/s]\u001b[A\n",
      " 79%|███████▉  | 56/71 [00:25<00:07,  2.02it/s]\u001b[A\n",
      " 80%|████████  | 57/71 [00:25<00:07,  1.99it/s]\u001b[A\n",
      " 82%|████████▏ | 58/71 [00:26<00:05,  2.17it/s]\u001b[A\n",
      " 83%|████████▎ | 59/71 [00:26<00:05,  2.34it/s]\u001b[A\n",
      " 85%|████████▍ | 60/71 [00:26<00:05,  2.19it/s]\u001b[A\n",
      " 86%|████████▌ | 61/71 [00:27<00:04,  2.22it/s]\u001b[A\n",
      " 87%|████████▋ | 62/71 [00:27<00:04,  2.10it/s]\u001b[A\n",
      " 89%|████████▊ | 63/71 [00:28<00:03,  2.22it/s]\u001b[A\n",
      " 90%|█████████ | 64/71 [00:28<00:03,  2.16it/s]\u001b[A\n",
      " 92%|█████████▏| 65/71 [00:29<00:02,  2.13it/s]\u001b[A\n",
      " 93%|█████████▎| 66/71 [00:29<00:02,  2.18it/s]\u001b[A\n",
      " 94%|█████████▍| 67/71 [00:30<00:01,  2.14it/s]\u001b[A\n",
      " 96%|█████████▌| 68/71 [00:30<00:01,  2.01it/s]\u001b[A\n",
      " 97%|█████████▋| 69/71 [00:31<00:01,  1.97it/s]\u001b[A\n",
      " 99%|█████████▊| 70/71 [00:31<00:00,  2.20it/s]\u001b[A\n",
      "100%|██████████| 71/71 [00:32<00:00,  2.20it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:32<04:49, 32.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6722388042950295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/71 [00:00<00:35,  1.95it/s]\u001b[A\n",
      "  3%|▎         | 2/71 [00:00<00:30,  2.27it/s]\u001b[A\n",
      "  4%|▍         | 3/71 [00:01<00:32,  2.08it/s]\u001b[A\n",
      "  6%|▌         | 4/71 [00:01<00:32,  2.08it/s]\u001b[A\n",
      "  7%|▋         | 5/71 [00:02<00:32,  2.05it/s]\u001b[A\n",
      "  8%|▊         | 6/71 [00:02<00:31,  2.05it/s]\u001b[A\n",
      " 10%|▉         | 7/71 [00:03<00:29,  2.14it/s]\u001b[A\n",
      " 11%|█▏        | 8/71 [00:03<00:31,  2.01it/s]\u001b[A\n",
      " 13%|█▎        | 9/71 [00:04<00:28,  2.16it/s]\u001b[A\n",
      " 14%|█▍        | 10/71 [00:04<00:28,  2.16it/s]\u001b[A\n",
      " 15%|█▌        | 11/71 [00:05<00:28,  2.14it/s]\u001b[A\n",
      " 17%|█▋        | 12/71 [00:05<00:27,  2.14it/s]\u001b[A\n",
      " 18%|█▊        | 13/71 [00:06<00:25,  2.30it/s]\u001b[A\n",
      " 20%|█▉        | 14/71 [00:06<00:25,  2.27it/s]\u001b[A\n",
      " 21%|██        | 15/71 [00:06<00:24,  2.30it/s]\u001b[A\n",
      " 23%|██▎       | 16/71 [00:07<00:22,  2.46it/s]\u001b[A\n",
      " 24%|██▍       | 17/71 [00:07<00:24,  2.20it/s]\u001b[A\n",
      " 25%|██▌       | 18/71 [00:08<00:25,  2.11it/s]\u001b[A\n",
      " 27%|██▋       | 19/71 [00:08<00:23,  2.19it/s]\u001b[A\n",
      " 28%|██▊       | 20/71 [00:09<00:24,  2.09it/s]\u001b[A\n",
      " 30%|██▉       | 21/71 [00:09<00:22,  2.18it/s]\u001b[A\n",
      " 31%|███       | 22/71 [00:10<00:24,  2.01it/s]\u001b[A\n",
      " 32%|███▏      | 23/71 [00:10<00:22,  2.17it/s]\u001b[A\n",
      " 34%|███▍      | 24/71 [00:11<00:23,  2.02it/s]\u001b[A\n",
      " 35%|███▌      | 25/71 [00:11<00:22,  2.04it/s]\u001b[A\n",
      " 37%|███▋      | 26/71 [00:12<00:22,  2.03it/s]\u001b[A\n",
      " 38%|███▊      | 27/71 [00:12<00:22,  2.00it/s]\u001b[A\n",
      " 39%|███▉      | 28/71 [00:13<00:20,  2.08it/s]\u001b[A\n",
      " 41%|████      | 29/71 [00:13<00:19,  2.11it/s]\u001b[A\n",
      " 42%|████▏     | 30/71 [00:14<00:18,  2.19it/s]\u001b[A\n",
      " 44%|████▎     | 31/71 [00:14<00:19,  2.04it/s]\u001b[A\n",
      " 45%|████▌     | 32/71 [00:15<00:19,  2.01it/s]\u001b[A\n",
      " 46%|████▋     | 33/71 [00:15<00:18,  2.07it/s]\u001b[A\n",
      " 48%|████▊     | 34/71 [00:16<00:17,  2.07it/s]\u001b[A\n",
      " 49%|████▉     | 35/71 [00:16<00:17,  2.06it/s]\u001b[A\n",
      " 51%|█████     | 36/71 [00:16<00:16,  2.15it/s]\u001b[A\n",
      " 52%|█████▏    | 37/71 [00:17<00:15,  2.19it/s]\u001b[A\n",
      " 54%|█████▎    | 38/71 [00:17<00:14,  2.22it/s]\u001b[A\n",
      " 55%|█████▍    | 39/71 [00:18<00:14,  2.25it/s]\u001b[A\n",
      " 56%|█████▋    | 40/71 [00:18<00:13,  2.27it/s]\u001b[A\n",
      " 58%|█████▊    | 41/71 [00:19<00:13,  2.17it/s]\u001b[A\n",
      " 59%|█████▉    | 42/71 [00:19<00:13,  2.13it/s]\u001b[A\n",
      " 61%|██████    | 43/71 [00:20<00:13,  2.13it/s]\u001b[A\n",
      " 62%|██████▏   | 44/71 [00:20<00:12,  2.20it/s]\u001b[A\n",
      " 63%|██████▎   | 45/71 [00:21<00:12,  2.16it/s]\u001b[A\n",
      " 65%|██████▍   | 46/71 [00:21<00:11,  2.12it/s]\u001b[A\n",
      " 66%|██████▌   | 47/71 [00:22<00:11,  2.01it/s]\u001b[A\n",
      " 68%|██████▊   | 48/71 [00:22<00:10,  2.10it/s]\u001b[A\n",
      " 69%|██████▉   | 49/71 [00:23<00:10,  2.09it/s]\u001b[A\n",
      " 70%|███████   | 50/71 [00:23<00:10,  2.08it/s]\u001b[A\n",
      " 72%|███████▏  | 51/71 [00:23<00:09,  2.09it/s]\u001b[A\n",
      " 73%|███████▎  | 52/71 [00:24<00:08,  2.15it/s]\u001b[A\n",
      " 75%|███████▍  | 53/71 [00:24<00:08,  2.13it/s]\u001b[A\n",
      " 76%|███████▌  | 54/71 [00:25<00:08,  2.07it/s]\u001b[A\n",
      " 77%|███████▋  | 55/71 [00:25<00:07,  2.01it/s]\u001b[A\n",
      " 79%|███████▉  | 56/71 [00:26<00:07,  2.11it/s]\u001b[A\n",
      " 80%|████████  | 57/71 [00:26<00:06,  2.25it/s]\u001b[A\n",
      " 82%|████████▏ | 58/71 [00:27<00:05,  2.19it/s]\u001b[A\n",
      " 83%|████████▎ | 59/71 [00:27<00:05,  2.23it/s]\u001b[A\n",
      " 85%|████████▍ | 60/71 [00:28<00:04,  2.34it/s]\u001b[A\n",
      " 86%|████████▌ | 61/71 [00:28<00:04,  2.30it/s]\u001b[A\n",
      " 87%|████████▋ | 62/71 [00:28<00:03,  2.46it/s]\u001b[A\n",
      " 89%|████████▊ | 63/71 [00:29<00:03,  2.54it/s]\u001b[A\n",
      " 90%|█████████ | 64/71 [00:29<00:02,  2.75it/s]\u001b[A\n",
      " 92%|█████████▏| 65/71 [00:29<00:02,  2.92it/s]\u001b[A\n",
      " 93%|█████████▎| 66/71 [00:30<00:01,  2.68it/s]\u001b[A\n",
      " 94%|█████████▍| 67/71 [00:30<00:01,  2.41it/s]\u001b[A\n",
      " 96%|█████████▌| 68/71 [00:31<00:01,  2.43it/s]\u001b[A\n",
      " 97%|█████████▋| 69/71 [00:31<00:00,  2.34it/s]\u001b[A\n",
      " 99%|█████████▊| 70/71 [00:31<00:00,  2.44it/s]\u001b[A\n",
      "100%|██████████| 71/71 [00:32<00:00,  2.20it/s]\u001b[A\n",
      " 20%|██        | 2/10 [01:04<04:17, 32.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6214179582369159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/71 [00:00<00:26,  2.68it/s]\u001b[A\n",
      "  3%|▎         | 2/71 [00:00<00:34,  1.98it/s]\u001b[A\n",
      "  4%|▍         | 3/71 [00:01<00:32,  2.12it/s]\u001b[A\n",
      "  6%|▌         | 4/71 [00:01<00:33,  1.99it/s]\u001b[A\n",
      "  7%|▋         | 5/71 [00:02<00:34,  1.90it/s]\u001b[A\n",
      "  8%|▊         | 6/71 [00:02<00:31,  2.05it/s]\u001b[A\n",
      " 10%|▉         | 7/71 [00:03<00:28,  2.26it/s]\u001b[A\n",
      " 11%|█▏        | 8/71 [00:03<00:28,  2.20it/s]\u001b[A\n",
      " 13%|█▎        | 9/71 [00:04<00:29,  2.13it/s]\u001b[A\n",
      " 14%|█▍        | 10/71 [00:04<00:29,  2.07it/s]\u001b[A\n",
      " 15%|█▌        | 11/71 [00:05<00:29,  2.03it/s]\u001b[A\n",
      " 17%|█▋        | 12/71 [00:05<00:29,  2.01it/s]\u001b[A\n",
      " 18%|█▊        | 13/71 [00:06<00:27,  2.10it/s]\u001b[A\n",
      " 20%|█▉        | 14/71 [00:06<00:27,  2.06it/s]\u001b[A\n",
      " 21%|██        | 15/71 [00:07<00:27,  2.04it/s]\u001b[A\n",
      " 23%|██▎       | 16/71 [00:07<00:25,  2.14it/s]\u001b[A\n",
      " 24%|██▍       | 17/71 [00:08<00:26,  2.00it/s]\u001b[A\n",
      " 25%|██▌       | 18/71 [00:08<00:25,  2.11it/s]\u001b[A\n",
      " 27%|██▋       | 19/71 [00:09<00:23,  2.23it/s]\u001b[A\n",
      " 28%|██▊       | 20/71 [00:09<00:22,  2.23it/s]\u001b[A\n",
      " 30%|██▉       | 21/71 [00:09<00:23,  2.14it/s]\u001b[A\n",
      " 31%|███       | 22/71 [00:10<00:21,  2.29it/s]\u001b[A\n",
      " 32%|███▏      | 23/71 [00:10<00:20,  2.36it/s]\u001b[A\n",
      " 34%|███▍      | 24/71 [00:11<00:22,  2.13it/s]\u001b[A\n",
      " 35%|███▌      | 25/71 [00:11<00:20,  2.20it/s]\u001b[A\n",
      " 37%|███▋      | 26/71 [00:12<00:19,  2.31it/s]\u001b[A\n",
      " 38%|███▊      | 27/71 [00:12<00:18,  2.44it/s]\u001b[A\n",
      " 39%|███▉      | 28/71 [00:12<00:17,  2.41it/s]\u001b[A\n",
      " 41%|████      | 29/71 [00:13<00:15,  2.63it/s]\u001b[A\n",
      " 42%|████▏     | 30/71 [00:13<00:16,  2.42it/s]\u001b[A\n",
      " 44%|████▎     | 31/71 [00:14<00:16,  2.40it/s]\u001b[A\n",
      " 45%|████▌     | 32/71 [00:14<00:16,  2.42it/s]\u001b[A\n",
      " 46%|████▋     | 33/71 [00:15<00:16,  2.33it/s]\u001b[A\n",
      " 48%|████▊     | 34/71 [00:15<00:16,  2.26it/s]\u001b[A\n",
      " 49%|████▉     | 35/71 [00:15<00:15,  2.26it/s]\u001b[A\n",
      " 51%|█████     | 36/71 [00:16<00:14,  2.40it/s]\u001b[A\n",
      " 52%|█████▏    | 37/71 [00:16<00:15,  2.23it/s]\u001b[A\n",
      " 54%|█████▎    | 38/71 [00:17<00:15,  2.12it/s]\u001b[A\n",
      " 55%|█████▍    | 39/71 [00:17<00:15,  2.02it/s]\u001b[A\n",
      " 56%|█████▋    | 40/71 [00:18<00:15,  2.02it/s]\u001b[A\n",
      " 58%|█████▊    | 41/71 [00:18<00:14,  2.12it/s]\u001b[A\n",
      " 59%|█████▉    | 42/71 [00:19<00:12,  2.28it/s]\u001b[A\n",
      " 61%|██████    | 43/71 [00:19<00:12,  2.19it/s]\u001b[A\n",
      " 62%|██████▏   | 44/71 [00:20<00:12,  2.22it/s]\u001b[A\n",
      " 63%|██████▎   | 45/71 [00:20<00:11,  2.36it/s]\u001b[A\n",
      " 65%|██████▍   | 46/71 [00:20<00:10,  2.36it/s]\u001b[A\n",
      " 66%|██████▌   | 47/71 [00:21<00:10,  2.23it/s]\u001b[A\n",
      " 68%|██████▊   | 48/71 [00:21<00:10,  2.25it/s]\u001b[A\n",
      " 69%|██████▉   | 49/71 [00:22<00:10,  2.07it/s]\u001b[A\n",
      " 70%|███████   | 50/71 [00:22<00:09,  2.21it/s]\u001b[A\n",
      " 72%|███████▏  | 51/71 [00:23<00:09,  2.01it/s]\u001b[A\n",
      " 73%|███████▎  | 52/71 [00:23<00:09,  2.03it/s]\u001b[A\n",
      " 75%|███████▍  | 53/71 [00:24<00:08,  2.08it/s]\u001b[A\n",
      " 76%|███████▌  | 54/71 [00:24<00:07,  2.18it/s]\u001b[A\n",
      " 77%|███████▋  | 55/71 [00:25<00:07,  2.23it/s]\u001b[A\n",
      " 79%|███████▉  | 56/71 [00:25<00:06,  2.19it/s]\u001b[A\n",
      " 80%|████████  | 57/71 [00:26<00:06,  2.15it/s]\u001b[A\n",
      " 82%|████████▏ | 58/71 [00:26<00:06,  2.14it/s]\u001b[A\n",
      " 83%|████████▎ | 59/71 [00:27<00:05,  2.10it/s]\u001b[A\n",
      " 85%|████████▍ | 60/71 [00:27<00:05,  2.15it/s]\u001b[A\n",
      " 86%|████████▌ | 61/71 [00:28<00:04,  2.07it/s]\u001b[A\n",
      " 87%|████████▋ | 62/71 [00:28<00:04,  2.11it/s]\u001b[A\n",
      " 89%|████████▊ | 63/71 [00:28<00:03,  2.10it/s]\u001b[A\n",
      " 90%|█████████ | 64/71 [00:29<00:03,  2.14it/s]\u001b[A\n",
      " 92%|█████████▏| 65/71 [00:29<00:02,  2.10it/s]\u001b[A\n",
      " 93%|█████████▎| 66/71 [00:30<00:02,  2.19it/s]\u001b[A\n",
      " 94%|█████████▍| 67/71 [00:30<00:01,  2.22it/s]\u001b[A\n",
      " 96%|█████████▌| 68/71 [00:31<00:01,  2.14it/s]\u001b[A\n",
      " 97%|█████████▋| 69/71 [00:31<00:00,  2.25it/s]\u001b[A\n",
      " 99%|█████████▊| 70/71 [00:32<00:00,  2.25it/s]\u001b[A\n",
      "100%|██████████| 71/71 [00:32<00:00,  2.18it/s]\u001b[A\n",
      " 30%|███       | 3/10 [01:36<03:46, 32.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.605287535929344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/71 [00:00<00:34,  2.03it/s]\u001b[A\n",
      "  3%|▎         | 2/71 [00:00<00:29,  2.37it/s]\u001b[A\n",
      "  4%|▍         | 3/71 [00:01<00:30,  2.20it/s]\u001b[A\n",
      "  6%|▌         | 4/71 [00:01<00:31,  2.15it/s]\u001b[A\n",
      "  7%|▋         | 5/71 [00:02<00:31,  2.09it/s]\u001b[A\n",
      "  8%|▊         | 6/71 [00:02<00:28,  2.25it/s]\u001b[A\n",
      " 10%|▉         | 7/71 [00:03<00:27,  2.33it/s]\u001b[A\n",
      " 11%|█▏        | 8/71 [00:03<00:26,  2.36it/s]\u001b[A\n",
      " 13%|█▎        | 9/71 [00:03<00:24,  2.51it/s]\u001b[A\n",
      " 14%|█▍        | 10/71 [00:04<00:23,  2.62it/s]\u001b[A\n",
      " 15%|█▌        | 11/71 [00:04<00:23,  2.60it/s]\u001b[A\n",
      " 17%|█▋        | 12/71 [00:05<00:23,  2.56it/s]\u001b[A\n",
      " 18%|█▊        | 13/71 [00:05<00:23,  2.49it/s]\u001b[A\n",
      " 20%|█▉        | 14/71 [00:05<00:23,  2.38it/s]\u001b[A\n",
      " 21%|██        | 15/71 [00:06<00:23,  2.40it/s]\u001b[A\n",
      " 23%|██▎       | 16/71 [00:06<00:23,  2.37it/s]\u001b[A\n",
      " 24%|██▍       | 17/71 [00:07<00:22,  2.40it/s]\u001b[A\n",
      " 25%|██▌       | 18/71 [00:07<00:22,  2.39it/s]\u001b[A\n",
      " 27%|██▋       | 19/71 [00:07<00:21,  2.48it/s]\u001b[A\n",
      " 28%|██▊       | 20/71 [00:08<00:21,  2.40it/s]\u001b[A\n",
      " 30%|██▉       | 21/71 [00:08<00:21,  2.29it/s]\u001b[A\n",
      " 31%|███       | 22/71 [00:09<00:20,  2.34it/s]\u001b[A\n",
      " 32%|███▏      | 23/71 [00:09<00:21,  2.20it/s]\u001b[A\n",
      " 34%|███▍      | 24/71 [00:10<00:19,  2.35it/s]\u001b[A\n",
      " 35%|███▌      | 25/71 [00:10<00:20,  2.22it/s]\u001b[A\n",
      " 37%|███▋      | 26/71 [00:11<00:20,  2.16it/s]\u001b[A\n",
      " 38%|███▊      | 27/71 [00:11<00:20,  2.19it/s]\u001b[A\n",
      " 39%|███▉      | 28/71 [00:12<00:19,  2.22it/s]\u001b[A\n",
      " 41%|████      | 29/71 [00:12<00:18,  2.26it/s]\u001b[A\n",
      " 42%|████▏     | 30/71 [00:12<00:18,  2.26it/s]\u001b[A\n",
      " 44%|████▎     | 31/71 [00:13<00:17,  2.22it/s]\u001b[A\n",
      " 45%|████▌     | 32/71 [00:13<00:17,  2.24it/s]\u001b[A\n",
      " 46%|████▋     | 33/71 [00:14<00:17,  2.14it/s]\u001b[A\n",
      " 48%|████▊     | 34/71 [00:14<00:18,  2.02it/s]\u001b[A\n",
      " 49%|████▉     | 35/71 [00:15<00:17,  2.03it/s]\u001b[A\n",
      " 51%|█████     | 36/71 [00:15<00:17,  2.03it/s]\u001b[A\n",
      " 52%|█████▏    | 37/71 [00:16<00:17,  1.90it/s]\u001b[A\n",
      " 54%|█████▎    | 38/71 [00:16<00:17,  1.93it/s]\u001b[A\n",
      " 55%|█████▍    | 39/71 [00:17<00:15,  2.03it/s]\u001b[A\n",
      " 56%|█████▋    | 40/71 [00:17<00:14,  2.13it/s]\u001b[A\n",
      " 58%|█████▊    | 41/71 [00:18<00:14,  2.11it/s]\u001b[A\n",
      " 59%|█████▉    | 42/71 [00:18<00:13,  2.19it/s]\u001b[A\n",
      " 61%|██████    | 43/71 [00:19<00:13,  2.14it/s]\u001b[A\n",
      " 62%|██████▏   | 44/71 [00:19<00:12,  2.19it/s]\u001b[A\n",
      " 63%|██████▎   | 45/71 [00:20<00:11,  2.23it/s]\u001b[A\n",
      " 65%|██████▍   | 46/71 [00:20<00:11,  2.26it/s]\u001b[A\n",
      " 66%|██████▌   | 47/71 [00:21<00:11,  2.10it/s]\u001b[A\n",
      " 68%|██████▊   | 48/71 [00:21<00:11,  2.05it/s]\u001b[A\n",
      " 69%|██████▉   | 49/71 [00:21<00:10,  2.12it/s]\u001b[A\n",
      " 70%|███████   | 50/71 [00:22<00:09,  2.23it/s]\u001b[A\n",
      " 72%|███████▏  | 51/71 [00:22<00:08,  2.26it/s]\u001b[A\n",
      " 73%|███████▎  | 52/71 [00:23<00:08,  2.15it/s]\u001b[A\n",
      " 75%|███████▍  | 53/71 [00:23<00:08,  2.01it/s]\u001b[A\n",
      " 76%|███████▌  | 54/71 [00:24<00:08,  2.04it/s]\u001b[A\n",
      " 77%|███████▋  | 55/71 [00:24<00:07,  2.14it/s]\u001b[A\n",
      " 79%|███████▉  | 56/71 [00:25<00:06,  2.25it/s]\u001b[A\n",
      " 80%|████████  | 57/71 [00:25<00:06,  2.11it/s]\u001b[A\n",
      " 82%|████████▏ | 58/71 [00:26<00:06,  2.13it/s]\u001b[A\n",
      " 83%|████████▎ | 59/71 [00:26<00:05,  2.21it/s]\u001b[A\n",
      " 85%|████████▍ | 60/71 [00:27<00:05,  2.14it/s]\u001b[A\n",
      " 86%|████████▌ | 61/71 [00:27<00:04,  2.26it/s]\u001b[A\n",
      " 87%|████████▋ | 62/71 [00:27<00:04,  2.17it/s]\u001b[A\n",
      " 89%|████████▊ | 63/71 [00:28<00:03,  2.35it/s]\u001b[A\n",
      " 90%|█████████ | 64/71 [00:28<00:03,  2.26it/s]\u001b[A\n",
      " 92%|█████████▏| 65/71 [00:29<00:02,  2.17it/s]\u001b[A\n",
      " 93%|█████████▎| 66/71 [00:29<00:02,  2.09it/s]\u001b[A\n",
      " 94%|█████████▍| 67/71 [00:30<00:01,  2.24it/s]\u001b[A\n",
      " 96%|█████████▌| 68/71 [00:30<00:01,  2.31it/s]\u001b[A\n",
      " 97%|█████████▋| 69/71 [00:31<00:00,  2.18it/s]\u001b[A\n",
      " 99%|█████████▊| 70/71 [00:31<00:00,  2.23it/s]\u001b[A\n",
      "100%|██████████| 71/71 [00:31<00:00,  2.23it/s]\u001b[A\n",
      " 40%|████      | 4/10 [02:08<03:13, 32.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.5748615367731578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/71 [00:00<00:33,  2.07it/s]\u001b[A\n",
      "  3%|▎         | 2/71 [00:00<00:26,  2.59it/s]\u001b[A\n",
      "  4%|▍         | 3/71 [00:01<00:31,  2.19it/s]\u001b[A\n",
      "  6%|▌         | 4/71 [00:01<00:30,  2.20it/s]\u001b[A\n",
      "  7%|▋         | 5/71 [00:02<00:28,  2.35it/s]\u001b[A\n",
      "  8%|▊         | 6/71 [00:02<00:26,  2.44it/s]\u001b[A\n",
      " 10%|▉         | 7/71 [00:02<00:26,  2.43it/s]\u001b[A\n",
      " 11%|█▏        | 8/71 [00:03<00:26,  2.38it/s]\u001b[A\n",
      " 13%|█▎        | 9/71 [00:03<00:26,  2.32it/s]\u001b[A\n",
      " 14%|█▍        | 10/71 [00:04<00:25,  2.41it/s]\u001b[A\n",
      " 15%|█▌        | 11/71 [00:04<00:25,  2.37it/s]\u001b[A\n",
      " 17%|█▋        | 12/71 [00:05<00:24,  2.38it/s]\u001b[A\n",
      " 18%|█▊        | 13/71 [00:05<00:27,  2.13it/s]\u001b[A\n",
      " 20%|█▉        | 14/71 [00:06<00:25,  2.23it/s]\u001b[A\n",
      " 21%|██        | 15/71 [00:06<00:26,  2.13it/s]\u001b[A\n",
      " 23%|██▎       | 16/71 [00:07<00:26,  2.10it/s]\u001b[A\n",
      " 24%|██▍       | 17/71 [00:07<00:26,  2.07it/s]\u001b[A\n",
      " 25%|██▌       | 18/71 [00:08<00:25,  2.08it/s]\u001b[A\n",
      " 27%|██▋       | 19/71 [00:08<00:23,  2.25it/s]\u001b[A\n",
      " 28%|██▊       | 20/71 [00:08<00:24,  2.12it/s]\u001b[A\n",
      " 30%|██▉       | 21/71 [00:09<00:22,  2.23it/s]\u001b[A\n",
      " 31%|███       | 22/71 [00:09<00:20,  2.40it/s]\u001b[A\n",
      " 32%|███▏      | 23/71 [00:10<00:20,  2.29it/s]\u001b[A\n",
      " 34%|███▍      | 24/71 [00:10<00:21,  2.23it/s]\u001b[A\n",
      " 35%|███▌      | 25/71 [00:11<00:20,  2.26it/s]\u001b[A\n",
      " 37%|███▋      | 26/71 [00:11<00:18,  2.38it/s]\u001b[A\n",
      " 38%|███▊      | 27/71 [00:11<00:18,  2.43it/s]\u001b[A\n",
      " 39%|███▉      | 28/71 [00:12<00:18,  2.32it/s]\u001b[A\n",
      " 41%|████      | 29/71 [00:12<00:18,  2.22it/s]\u001b[A\n",
      " 42%|████▏     | 30/71 [00:13<00:18,  2.16it/s]\u001b[A\n",
      " 44%|████▎     | 31/71 [00:13<00:17,  2.30it/s]\u001b[A\n",
      " 45%|████▌     | 32/71 [00:14<00:17,  2.21it/s]\u001b[A\n",
      " 46%|████▋     | 33/71 [00:14<00:17,  2.21it/s]\u001b[A\n",
      " 48%|████▊     | 34/71 [00:15<00:16,  2.19it/s]\u001b[A\n",
      " 49%|████▉     | 35/71 [00:15<00:15,  2.26it/s]\u001b[A\n",
      " 51%|█████     | 36/71 [00:15<00:16,  2.18it/s]\u001b[A\n",
      " 52%|█████▏    | 37/71 [00:16<00:15,  2.16it/s]\u001b[A\n",
      " 54%|█████▎    | 38/71 [00:17<00:16,  1.99it/s]\u001b[A\n",
      " 55%|█████▍    | 39/71 [00:17<00:16,  1.97it/s]\u001b[A\n",
      " 56%|█████▋    | 40/71 [00:18<00:15,  1.97it/s]\u001b[A\n",
      " 58%|█████▊    | 41/71 [00:18<00:15,  1.99it/s]\u001b[A\n",
      " 59%|█████▉    | 42/71 [00:19<00:14,  2.03it/s]\u001b[A\n",
      " 61%|██████    | 43/71 [00:19<00:13,  2.05it/s]\u001b[A\n",
      " 62%|██████▏   | 44/71 [00:20<00:13,  2.01it/s]\u001b[A\n",
      " 63%|██████▎   | 45/71 [00:20<00:12,  2.04it/s]\u001b[A\n",
      " 65%|██████▍   | 46/71 [00:20<00:11,  2.18it/s]\u001b[A\n",
      " 66%|██████▌   | 47/71 [00:21<00:10,  2.23it/s]\u001b[A\n",
      " 68%|██████▊   | 48/71 [00:21<00:10,  2.25it/s]\u001b[A\n",
      " 69%|██████▉   | 49/71 [00:22<00:09,  2.25it/s]\u001b[A\n",
      " 70%|███████   | 50/71 [00:22<00:09,  2.16it/s]\u001b[A\n",
      " 72%|███████▏  | 51/71 [00:23<00:09,  2.19it/s]\u001b[A\n",
      " 73%|███████▎  | 52/71 [00:23<00:08,  2.23it/s]\u001b[A\n",
      " 75%|███████▍  | 53/71 [00:24<00:08,  2.19it/s]\u001b[A\n",
      " 76%|███████▌  | 54/71 [00:24<00:06,  2.44it/s]\u001b[A\n",
      " 77%|███████▋  | 55/71 [00:24<00:06,  2.33it/s]\u001b[A\n",
      " 79%|███████▉  | 56/71 [00:25<00:06,  2.29it/s]\u001b[A\n",
      " 80%|████████  | 57/71 [00:25<00:05,  2.35it/s]\u001b[A\n",
      " 82%|████████▏ | 58/71 [00:26<00:05,  2.36it/s]\u001b[A\n",
      " 83%|████████▎ | 59/71 [00:26<00:05,  2.37it/s]\u001b[A\n",
      " 85%|████████▍ | 60/71 [00:26<00:04,  2.32it/s]\u001b[A\n",
      " 86%|████████▌ | 61/71 [00:27<00:04,  2.23it/s]\u001b[A\n",
      " 87%|████████▋ | 62/71 [00:27<00:04,  2.15it/s]\u001b[A\n",
      " 89%|████████▊ | 63/71 [00:28<00:03,  2.25it/s]\u001b[A\n",
      " 90%|█████████ | 64/71 [00:28<00:02,  2.38it/s]\u001b[A\n",
      " 92%|█████████▏| 65/71 [00:29<00:02,  2.32it/s]\u001b[A\n",
      " 93%|█████████▎| 66/71 [00:29<00:02,  2.43it/s]\u001b[A\n",
      " 94%|█████████▍| 67/71 [00:29<00:01,  2.38it/s]\u001b[A\n",
      " 96%|█████████▌| 68/71 [00:30<00:01,  2.30it/s]\u001b[A\n",
      " 97%|█████████▋| 69/71 [00:30<00:00,  2.31it/s]\u001b[A\n",
      " 99%|█████████▊| 70/71 [00:31<00:00,  2.18it/s]\u001b[A\n",
      "100%|██████████| 71/71 [00:31<00:00,  2.23it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [02:40<02:40, 32.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.5704924837804176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/71 [00:00<00:37,  1.88it/s]\u001b[A\n",
      "  3%|▎         | 2/71 [00:00<00:31,  2.19it/s]\u001b[A\n",
      "  4%|▍         | 3/71 [00:01<00:32,  2.11it/s]\u001b[A\n",
      "  6%|▌         | 4/71 [00:01<00:32,  2.08it/s]\u001b[A\n",
      "  7%|▋         | 5/71 [00:02<00:27,  2.39it/s]\u001b[A\n",
      "  8%|▊         | 6/71 [00:02<00:27,  2.32it/s]\u001b[A\n",
      " 10%|▉         | 7/71 [00:03<00:29,  2.19it/s]\u001b[A\n",
      " 11%|█▏        | 8/71 [00:03<00:29,  2.16it/s]\u001b[A\n",
      " 13%|█▎        | 9/71 [00:03<00:25,  2.42it/s]\u001b[A\n",
      " 14%|█▍        | 10/71 [00:04<00:26,  2.35it/s]\u001b[A\n",
      " 15%|█▌        | 11/71 [00:04<00:24,  2.45it/s]\u001b[A\n",
      " 17%|█▋        | 12/71 [00:05<00:22,  2.60it/s]\u001b[A\n",
      " 18%|█▊        | 13/71 [00:05<00:22,  2.63it/s]\u001b[A\n",
      " 20%|█▉        | 14/71 [00:05<00:23,  2.47it/s]\u001b[A\n",
      " 21%|██        | 15/71 [00:06<00:24,  2.30it/s]\u001b[A\n",
      " 23%|██▎       | 16/71 [00:07<00:26,  2.10it/s]\u001b[A\n",
      " 24%|██▍       | 17/71 [00:07<00:25,  2.15it/s]\u001b[A\n",
      " 25%|██▌       | 18/71 [00:07<00:25,  2.11it/s]\u001b[A\n",
      " 27%|██▋       | 19/71 [00:08<00:24,  2.16it/s]\u001b[A\n",
      " 28%|██▊       | 20/71 [00:08<00:20,  2.48it/s]\u001b[A\n",
      " 30%|██▉       | 21/71 [00:09<00:21,  2.35it/s]\u001b[A\n",
      " 31%|███       | 22/71 [00:09<00:20,  2.36it/s]\u001b[A\n",
      " 32%|███▏      | 23/71 [00:10<00:21,  2.21it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [02:51<02:51, 34.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 108\u001b[0m\n\u001b[1;32m    102\u001b[0m             total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m \u001b[43mtrain_triplet_loss_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfusion_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfusion_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfusion_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfusion_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtarget_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[98], line 85\u001b[0m, in \u001b[0;36mtrain_triplet_loss_model\u001b[0;34m(fusion_model, target_model, train_loader, fusion_optimizer, target_optimizer, epochs)\u001b[0m\n\u001b[1;32m     78\u001b[0m positive_embeddings \u001b[38;5;241m=\u001b[39m fusion_model(\n\u001b[1;32m     79\u001b[0m     description_title_emb\u001b[38;5;241m=\u001b[39mpositive_text_embs,\n\u001b[1;32m     80\u001b[0m     audio_text_emb\u001b[38;5;241m=\u001b[39mpositive_audio_embs,\n\u001b[1;32m     81\u001b[0m     video_emb\u001b[38;5;241m=\u001b[39mpositive_video_embs\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     84\u001b[0m negative_text_embs \u001b[38;5;241m=\u001b[39m text_model\u001b[38;5;241m.\u001b[39mencode(negative_text, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m negative_audio_embs \u001b[38;5;241m=\u001b[39m \u001b[43maudio_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegative_audio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     86\u001b[0m negative_video_embs \u001b[38;5;241m=\u001b[39m negative_video\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     88\u001b[0m negative_embeddings \u001b[38;5;241m=\u001b[39m fusion_model(\n\u001b[1;32m     89\u001b[0m     description_title_emb\u001b[38;5;241m=\u001b[39mnegative_text_embs,\n\u001b[1;32m     90\u001b[0m     audio_text_emb\u001b[38;5;241m=\u001b[39mnegative_audio_embs,\n\u001b[1;32m     91\u001b[0m     video_emb\u001b[38;5;241m=\u001b[39mnegative_video_embs\n\u001b[1;32m     92\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:597\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    589\u001b[0m             features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    590\u001b[0m                 (\n\u001b[1;32m    591\u001b[0m                     features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    595\u001b[0m             )\n\u001b[0;32m--> 597\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/util.py:1035\u001b[0m, in \u001b[0;36mbatch_to_device\u001b[0;34m(batch, target_device)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch[key], Tensor):\n\u001b[0;32m-> 1035\u001b[0m         batch[key] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fusion_optimizer = torch.optim.AdamW(fusion_model.parameters(), lr=3e-4)\n",
    "target_optimizer = torch.optim.AdamW(target_model.parameters(), lr=3e-4)\n",
    "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.classes = dataframe['tag_list'].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_class = self.data.iloc[idx]['tag_list']\n",
    "\n",
    "        positive_text = self.data.iloc[idx]['title_description']\n",
    "        positive_audio = self.data.iloc[idx]['audio_text']\n",
    "        positive_video = self.data.iloc[idx]['video_emb']\n",
    "\n",
    "        positive_samples = self.data[(self.data['tag_list'] == anchor_class) & (self.data.index != idx)]\n",
    "        if len(positive_samples) > 0:\n",
    "            anchor_sample = positive_samples.sample(1).iloc[0]\n",
    "        else:\n",
    "            anchor_sample = self.data.iloc[idx]\n",
    "\n",
    "        anchor_text = anchor_sample['title_description']\n",
    "        anchor_audio = anchor_sample['audio_text']\n",
    "        anchor_video = anchor_sample['video_emb']\n",
    "\n",
    "        negative_samples = self.data[self.data['tag_list'] != anchor_class]\n",
    "        negative_sample = negative_samples.sample(1).iloc[0]\n",
    "        negative_text = negative_sample['title_description']\n",
    "        negative_audio = negative_sample['audio_text']\n",
    "        negative_video = negative_sample['video_emb']\n",
    "\n",
    "        return (\n",
    "            anchor_text, anchor_audio, anchor_video,\n",
    "            positive_text, positive_audio, positive_video,\n",
    "            negative_text, negative_audio, negative_video\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = TripletDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "def tokenize_batch(texts):\n",
    "    tokens = general_tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    return {key: value.to('cuda') for key, value in tokens.items()}\n",
    "\n",
    "def train_triplet_loss_model(fusion_model, target_model, train_loader,\n",
    "                             fusion_optimizer, target_optimizer, epochs=2):\n",
    "    fusion_model.train()\n",
    "    target_model.train()\n",
    "    text_model.train()\n",
    "    audio_model.train()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader):\n",
    "            (anchor_text, anchor_audio, anchor_video,\n",
    "             positive_text, positive_audio, positive_video,\n",
    "             negative_text, negative_audio, negative_video) = batch\n",
    "\n",
    "            anchor_text_embs = text_model.encode(anchor_text, convert_to_tensor=True).unsqueeze(1)\n",
    "            anchor_audio_embs = audio_model.encode(anchor_audio, convert_to_tensor=True).unsqueeze(1)\n",
    "            anchor_video_embs = anchor_video.to('cuda')\n",
    "\n",
    "            anchor_embeddings = fusion_model(\n",
    "                description_title_emb=anchor_text_embs,\n",
    "                audio_text_emb=anchor_audio_embs,\n",
    "                video_emb=anchor_video_embs\n",
    "            )\n",
    "\n",
    "            positive_text_embs = text_model.encode(positive_text, convert_to_tensor=True).unsqueeze(1)\n",
    "            positive_audio_embs = audio_model.encode(positive_audio, convert_to_tensor=True).unsqueeze(1)\n",
    "            positive_video_embs = positive_video.to('cuda')\n",
    "\n",
    "            positive_embeddings = fusion_model(\n",
    "                description_title_emb=positive_text_embs,\n",
    "                audio_text_emb=positive_audio_embs,\n",
    "                video_emb=positive_video_embs\n",
    "            )\n",
    "\n",
    "            negative_text_embs = text_model.encode(negative_text, convert_to_tensor=True).unsqueeze(1)\n",
    "            negative_audio_embs = audio_model.encode(negative_audio, convert_to_tensor=True).unsqueeze(1)\n",
    "            negative_video_embs = negative_video.to('cuda')\n",
    "\n",
    "            negative_embeddings = fusion_model(\n",
    "                description_title_emb=negative_text_embs,\n",
    "                audio_text_emb=negative_audio_embs,\n",
    "                video_emb=negative_video_embs\n",
    "            )\n",
    "\n",
    "            loss = triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings)\n",
    "\n",
    "            fusion_optimizer.zero_grad()\n",
    "            target_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            fusion_optimizer.step()\n",
    "            target_optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "\n",
    "\n",
    "train_triplet_loss_model(fusion_model=fusion_model, target_model=target_model,\n",
    "                         train_loader=train_loader, fusion_optimizer=fusion_optimizer,\n",
    "                         target_optimizer=target_optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0eMjYEt8o9v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "EnIt-SiG8pAb"
   },
   "outputs": [],
   "source": [
    "# METRICS\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def iou_metric(ground_truth, predictions):\n",
    "    iou =  len(set.intersection(set(ground_truth), set(predictions)))\n",
    "    iou = iou/(len(set(ground_truth).union(set(predictions))))\n",
    "    return iou\n",
    "\n",
    "def split_tags(tag_list):\n",
    "    final_tag_list = []\n",
    "    for tag in tag_list:\n",
    "        tags = tag.split(\": \")\n",
    "        if len(tags) == 3:\n",
    "            final_tag_list.append(tags[0])\n",
    "            final_tag_list.append(tags[0] + \": \" + tags[1])\n",
    "            final_tag_list.append(tags[0]+ \": \" + tags[1] + \": \" + tags[2])\n",
    "        elif len(tags) == 2:\n",
    "            final_tag_list.append(tags[0])\n",
    "            final_tag_list.append(tags[0] + \": \" + tags[1])\n",
    "        elif len(tags) == 1:\n",
    "            final_tag_list.append(tags[0])\n",
    "        else:\n",
    "            print(\"NOT IMPLEMENTED!!!!\", tag)\n",
    "    return final_tag_list\n",
    "\n",
    "def find_iou_for_sample_submission(pred_submission, true_submission):\n",
    "    ground_truth_df = true_submission\n",
    "    ground_truth_df[\"tag_list\"] = ground_truth_df[\"tag_list\"].str.split(', ')\n",
    "    ground_truth_df[\"tags_split\"] = ground_truth_df[\"tag_list\"].apply(lambda l: split_tags(l))\n",
    "\n",
    "    predictions_df = pred_submission\n",
    "#     predictions_df[\"predicted_tags\"] = predictions_df[\"predicted_tags\"].apply(ast.literal_eval\n",
    "    predictions_df[\"predicted_tags_split\"] = predictions_df[\"predicted_tags\"] = predictions_df[\"predicted_tags\"].apply(\n",
    "                                                                lambda l: split_tags(l) if not isinstance(l, float) else l\n",
    "                                                )\n",
    "\n",
    "    iou=0\n",
    "    counter = 0\n",
    "    for i, row in ground_truth_df.iterrows():\n",
    "        predicted_tags = predictions_df[predictions_df[\"video_id\"]==row[\"video_id\"]][\"predicted_tags_split\"].values[0]\n",
    "        iou_temp=iou_metric(row['tags_split'], predicted_tags)\n",
    "        iou+=iou_temp\n",
    "        counter+=1\n",
    "\n",
    "    return iou/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "CBeU4feL6PN-"
   },
   "outputs": [],
   "source": [
    "# INFERENCE (по test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "07SWaJ_iDgQ4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/image_processing_utils.py:41: UserWarning: The following named arguments are not valid for `VideoMAEImageProcessor.preprocess` and were ignored: 'padding'\n",
      "  return self.preprocess(images, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "video_model.eval()\n",
    "video_embs_dict_test = dict()\n",
    "video_embs_test = []\n",
    "for i in test_df.iterrows():\n",
    "  # видео эмбеддинги засовываем в test_df в новую колонку\n",
    "  video_path = \"/home/jovyan/lost+found/videos_2/\" + str(i[1].video_id) + \".mp4\" # поменять на директорию, где хранятся видео, типо video_id = \"folder/\" + video_id\n",
    "  if video_path in video_embs_dict_test:\n",
    "    video_embs_test.append(video_embs_dict_test[video_path])\n",
    "  else:\n",
    "    vr = VideoReader(video_path)\n",
    "    seg_len = len(vr)\n",
    "    clip_len = 32 # для конкретной модели (microsoft/xclip-base-patch16-zero-shot)\n",
    "    frame_sample_rate = 1\n",
    "    indices = sample_frame_indices(clip_len=clip_len, frame_sample_rate=frame_sample_rate, seg_len=seg_len)\n",
    "    video = vr.get_batch(indices).asnumpy()  # (clip_len, H, W, C)\n",
    "    inputs = processor(videos=list(video), return_tensors=\"pt\", padding=True).to('cuda')\n",
    "    pixel_values = inputs['pixel_values']\n",
    "    batch_size, num_frames, channels, height, width = pixel_values.shape\n",
    "    pixel_values = pixel_values.view(-1, channels, height, width)  # [batch_size * num_frames, channels, height, width]\n",
    "    inputs['pixel_values'] = pixel_values.to('cuda')\n",
    "    with torch.no_grad():\n",
    "      outputs = video_model(**inputs)\n",
    "    frame_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    frame_embeddings = frame_embeddings.view(batch_size, num_frames, -1)\n",
    "    # average pooling over frame_embeddings\n",
    "    video_embedding = frame_embeddings.mean(dim=1) # (batch_size, emb_size) # надеюсь emb_size=1024 иначе еще линейный слой\n",
    "    video_embs_test.append(video_embedding)\n",
    "    video_embs_dict_test[video_path] = video_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title_description</th>\n",
       "      <th>audio_text</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>video_emb</th>\n",
       "      <th>title_description_vector</th>\n",
       "      <th>audio_text_vector</th>\n",
       "      <th>common_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>a40df9cd5c1517f478b458d74081ab12</td>\n",
       "      <td>Title: Один выходной | Сезон 2 | Выпуск 1 | Ск...</td>\n",
       "      <td>Можно все, вообще нет правила и в этом кайф. Т...</td>\n",
       "      <td>События и достопримечательности: Активный отдых</td>\n",
       "      <td>[[tensor(-0.2840), tensor(-0.0927), tensor(-0....</td>\n",
       "      <td>[0.02019478, 0.021183835, -0.028113348, -0.039...</td>\n",
       "      <td>[0.0122921225, -0.0072347517, -0.012975653, -0...</td>\n",
       "      <td>[-0.07921195, -0.041533127, -0.03266341, -0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>fbbd10e0e69381ef8d56896392eef543</td>\n",
       "      <td>Title: Тот Самый Мент I Выпуск 74 I Начальник ...</td>\n",
       "      <td>Присаживайтесь в Москве</td>\n",
       "      <td>Массовая культура: Юмор и сатира</td>\n",
       "      <td>[[tensor(-0.3112), tensor(0.0429), tensor(-0.0...</td>\n",
       "      <td>[0.025576632, 0.012932097, -0.018839719, -0.06...</td>\n",
       "      <td>[0.019080197, 0.01883682, -0.023289552, -0.045...</td>\n",
       "      <td>[-0.084199436, -0.07979075, -0.09679501, -0.11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              video_id  \\\n",
       "377   a40df9cd5c1517f478b458d74081ab12   \n",
       "1175  fbbd10e0e69381ef8d56896392eef543   \n",
       "\n",
       "                                      title_description  \\\n",
       "377   Title: Один выходной | Сезон 2 | Выпуск 1 | Ск...   \n",
       "1175  Title: Тот Самый Мент I Выпуск 74 I Начальник ...   \n",
       "\n",
       "                                             audio_text  \\\n",
       "377   Можно все, вообще нет правила и в этом кайф. Т...   \n",
       "1175                            Присаживайтесь в Москве   \n",
       "\n",
       "                                             tag_list  \\\n",
       "377   События и достопримечательности: Активный отдых   \n",
       "1175                 Массовая культура: Юмор и сатира   \n",
       "\n",
       "                                              video_emb  \\\n",
       "377   [[tensor(-0.2840), tensor(-0.0927), tensor(-0....   \n",
       "1175  [[tensor(-0.3112), tensor(0.0429), tensor(-0.0...   \n",
       "\n",
       "                               title_description_vector  \\\n",
       "377   [0.02019478, 0.021183835, -0.028113348, -0.039...   \n",
       "1175  [0.025576632, 0.012932097, -0.018839719, -0.06...   \n",
       "\n",
       "                                      audio_text_vector  \\\n",
       "377   [0.0122921225, -0.0072347517, -0.012975653, -0...   \n",
       "1175  [0.019080197, 0.01883682, -0.023289552, -0.045...   \n",
       "\n",
       "                                          common_vector  \n",
       "377   [-0.07921195, -0.041533127, -0.03266341, -0.11...  \n",
       "1175  [-0.084199436, -0.07979075, -0.09679501, -0.11...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "ldRIwOSUDgQ4"
   },
   "outputs": [],
   "source": [
    "test_df['video_emb'] = [i.cpu().detach() for i in video_embs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "B1CeDwJ7Evsa"
   },
   "outputs": [],
   "source": [
    "test_df['title_description_vector'] = test_df['title_description'].apply(lambda l: text_model.encode(l, convert_to_tensor=True).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "l9XXIsb8Evsa"
   },
   "outputs": [],
   "source": [
    "test_df['audio_text_vector'] = test_df['audio_text'].apply(lambda l: audio_model.encode(l, convert_to_tensor=True).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19125/1084964683.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  video_emb = torch.tensor(l['video_emb']).unsqueeze(0).to('cuda')  # (1, video_emb_dim)\n"
     ]
    }
   ],
   "source": [
    "def compute_common_vector(l):\n",
    "    description_title_emb = torch.tensor(l['title_description_vector']).unsqueeze(0).unsqueeze(1).to('cuda')  # (1, 1, emb_dim)\n",
    "    audio_text_emb = torch.tensor(l['audio_text_vector']).unsqueeze(0).unsqueeze(1).to('cuda')  # (1, 1, emb_dim)\n",
    "    video_emb = torch.tensor(l['video_emb']).unsqueeze(0).to('cuda')  # (1, video_emb_dim)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        common_vector = fusion_model(\n",
    "            description_title_emb=description_title_emb,\n",
    "            audio_text_emb=audio_text_emb,\n",
    "            video_emb=video_emb\n",
    "        )  # (1, output_dim)\n",
    "\n",
    "    return common_vector.cpu().numpy()[0]\n",
    "\n",
    "test_df['common_vector'] = test_df.apply(compute_common_vector, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "611it [00:16, 37.24it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_tags():\n",
    "    target_model.eval()\n",
    "    tags = {}\n",
    "    with torch.no_grad():\n",
    "        for i, row in tqdm(taxonomy.iterrows()):\n",
    "            if isinstance(row['Уровень 1 (iab)'], str):\n",
    "                tags[row['Уровень 1 (iab)']] = target_model.encode(row['Уровень 1 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "            if isinstance(row['Уровень 2 (iab)'], str):\n",
    "                tags[row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']] = target_model.encode(row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "            if isinstance(row['Уровень 3 (iab)'], str):\n",
    "                tags[row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']+\": \"+row['Уровень 3 (iab)']] = target_model.encode(row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']+\": \"+row['Уровень 3 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "        return tags\n",
    "\n",
    "tags = get_tags()\n",
    "tags_list = list(tags.keys())\n",
    "vectors = np.array(list(tags.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "610\n"
     ]
    }
   ],
   "source": [
    "index = faiss.index_factory(dim, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "print(index.ntotal)\n",
    "index.add(vectors)\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title_description</th>\n",
       "      <th>audio_text</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>video_emb</th>\n",
       "      <th>title_description_vector</th>\n",
       "      <th>audio_text_vector</th>\n",
       "      <th>common_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>8a762b2f22accc32159926c8054fd8e9</td>\n",
       "      <td>Title: location | Pompeya - Odelay. Descriptio...</td>\n",
       "      <td>Маленький</td>\n",
       "      <td>Музыка и аудио: Разное (Музыка и аудио)</td>\n",
       "      <td>[[tensor(-0.2467), tensor(0.1080), tensor(-0.0...</td>\n",
       "      <td>[0.010618988, 0.018526142, -0.019410837, -0.04...</td>\n",
       "      <td>[-0.0023610704, 0.03212811, -0.014340383, -0.0...</td>\n",
       "      <td>[-0.09672257, -0.027643707, -0.037916858, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>78002eb306ae22e44147464bc45842f8</td>\n",
       "      <td>Title: Много половин. Акмаль и его девушка Саш...</td>\n",
       "      <td>Сложно не заметить легендарную кредитную карту...</td>\n",
       "      <td>Карьера</td>\n",
       "      <td>[[tensor(-0.6046), tensor(-0.0152), tensor(0.0...</td>\n",
       "      <td>[0.013182346, 0.016781544, -0.025050532, -0.02...</td>\n",
       "      <td>[0.011375706, 0.017268492, -0.037079215, -0.04...</td>\n",
       "      <td>[-0.07911661, -0.06265162, -0.11458967, -0.096...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              video_id  \\\n",
       "1030  8a762b2f22accc32159926c8054fd8e9   \n",
       "819   78002eb306ae22e44147464bc45842f8   \n",
       "\n",
       "                                      title_description  \\\n",
       "1030  Title: location | Pompeya - Odelay. Descriptio...   \n",
       "819   Title: Много половин. Акмаль и его девушка Саш...   \n",
       "\n",
       "                                             audio_text  \\\n",
       "1030                                          Маленький   \n",
       "819   Сложно не заметить легендарную кредитную карту...   \n",
       "\n",
       "                                     tag_list  \\\n",
       "1030  Музыка и аудио: Разное (Музыка и аудио)   \n",
       "819                                   Карьера   \n",
       "\n",
       "                                              video_emb  \\\n",
       "1030  [[tensor(-0.2467), tensor(0.1080), tensor(-0.0...   \n",
       "819   [[tensor(-0.6046), tensor(-0.0152), tensor(0.0...   \n",
       "\n",
       "                               title_description_vector  \\\n",
       "1030  [0.010618988, 0.018526142, -0.019410837, -0.04...   \n",
       "819   [0.013182346, 0.016781544, -0.025050532, -0.02...   \n",
       "\n",
       "                                      audio_text_vector  \\\n",
       "1030  [-0.0023610704, 0.03212811, -0.014340383, -0.0...   \n",
       "819   [0.011375706, 0.017268492, -0.037079215, -0.04...   \n",
       "\n",
       "                                          common_vector  \n",
       "1030  [-0.09672257, -0.027643707, -0.037916858, -0.0...  \n",
       "819   [-0.07911661, -0.06265162, -0.11458967, -0.096...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>predicted_tags</th>\n",
       "      <th>predicted_tags_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>441c3db4884b412ee3b99db89c350fe3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>df635402135e4ee4f14188be19f35c83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             video_id predicted_tags predicted_tags_split\n",
       "260  441c3db4884b412ee3b99db89c350fe3            NaN                  NaN\n",
       "893  df635402135e4ee4f14188be19f35c83            NaN                  NaN"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008244994110718492"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn = 1\n",
    "\n",
    "sample_submission = pd.DataFrame(data=data['video_id'].to_list(), columns=['video_id'])\n",
    "sample_submission['predicted_tags'] = np.nan\n",
    "sample_submission['predicted_tags'] = sample_submission['predicted_tags'].astype('object')\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "#   topn = int(model_num_tags.predict([row['common_vector']])[0])\n",
    "  \n",
    "  scores, predictions = index.search(np.array([row['common_vector']]), topn)\n",
    "  index_i = sample_submission[sample_submission.video_id == row.video_id].index\n",
    "  sample_submission.at[index_i[0], 'predicted_tags'] = [\n",
    "      tags_list[tag] for i, tag in enumerate(predictions[0])\n",
    "  ]\n",
    "\n",
    "test_df_copy = test_df.copy()\n",
    "find_iou_for_sample_submission(sample_submission, test_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woRHe4wdFIPK"
   },
   "outputs": [],
   "source": [
    "def get_tags():\n",
    "    tags = {}\n",
    "    for i, row in tqdm(taxonomy.iterrows()):\n",
    "        if isinstance(row['Уровень 1 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)']] = model.encode(row['Уровень 1 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "        if isinstance(row['Уровень 2 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']] = model.encode(row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "        if isinstance(row['Уровень 3 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']+\": \"+row['Уровень 3 (iab)']] = model.encode(row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']+\": \"+row['Уровень 3 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "    return tags\n",
    "\n",
    "tags = get_tags()\n",
    "tags_list = list(tags.keys())\n",
    "vectors = np.array(list(tags.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_xCgHSiFIRv"
   },
   "outputs": [],
   "source": [
    "index = faiss.index_factory(dim, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "print(index.ntotal)\n",
    "index.add(vectors)\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hmMNNVuBvm-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5ovCZcjBl8L"
   },
   "outputs": [],
   "source": [
    "topn = 1\n",
    "\n",
    "sample_submission = pd.DataFrame(data=test_df['video_id'].to_list(), columns=['video_id'])\n",
    "sample_submission['predicted_tags'] = np.nan\n",
    "sample_submission['predicted_tags'] = sample_submission['predicted_tags'].astype('object')\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "#   topn = int(model_num_tags.predict([row['common_vector']])[0])\n",
    "  scores, predictions = index.search(np.array([row['common_vector']]), topn)\n",
    "  index_i = sample_submission[sample_submission.video_id == row.video_id].index\n",
    "  sample_submission.at[index_i[0], 'predicted_tags'] = [\n",
    "      tags_list[tag] for i, tag in enumerate(predictions[0])\n",
    "  ]\n",
    "\n",
    "data_copy = data.copy()\n",
    "find_iou_for_sample_submission(sample_submission, data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1leOBs-tBYzF"
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"sample_submission.csv\", index_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fupNnO-cBY11"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bA81bxMrbPYR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLncaIwfbPdu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQZjY9xtbPg5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
